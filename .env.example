# Chutes Autopilot (OpenAI-compatible router) configuration

# Bind address for the HTTP server
LISTEN_ADDR=0.0.0.0:8080

# Logging (tracing-subscriber EnvFilter)
RUST_LOG=info

# Container runtime (Docker/Docker Compose)
# Non-root UID/GID used inside the container; override to match your host when mounting volumes.
APP_UID=10001
APP_GID=10001
APP_USER=autopilot
# Host port forwarded to LISTEN_ADDR in docker-compose
HOST_PORT=8080
# Rust toolchain used in container/CI builds
RUST_VERSION=1.93.1

# Upstream OpenAI-compatible backend base URL (Autopilot will call `${BACKEND_BASE_URL}/v1/chat/completions`)
BACKEND_BASE_URL=https://llm.chutes.ai

# Control-plane endpoints
# Model catalog is used as an authoritative allowlist of chat-capable models.
MODELS_URL=https://llm.chutes.ai/v1/models
MODELS_REFRESH_MS=300000
UTILIZATION_URL=https://api.chutes.ai/chutes/utilization
UTILIZATION_REFRESH_MS=5000

# Control-plane request timeout (applies to MODELS_URL and UTILIZATION_URL fetches)
CONTROL_PLANE_TIMEOUT_MS=10000

# Readiness
READYZ_MAX_SNAPSHOT_AGE_MS=20000
READYZ_MAX_ALLOWLIST_AGE_MS=600000

# Request limits
MAX_REQUEST_BYTES=1048576
MAX_MODEL_LIST_ITEMS=8

# Upstream timeouts (applied before any bytes are streamed to the client)
UPSTREAM_CONNECT_TIMEOUT_MS=2000
UPSTREAM_HEADER_TIMEOUT_MS=10000
UPSTREAM_FIRST_BODY_BYTE_TIMEOUT_MS=120000

# Stickiness
STICKY_TTL_SECS=1800
STICKY_MAX_ENTRIES=10000

# Notifications (optional; used by ralphie TTS helpers)
CHUTES_API_KEY=

# Proxy header trust (only enable when running behind a trusted reverse proxy)
TRUST_PROXY_HEADERS=false
# Comma-separated CIDRs for trusted proxies (only used when TRUST_PROXY_HEADERS=true)
TRUSTED_PROXY_CIDRS=

# ---- Optional: Caddy sidecar (docker-compose) ----
# If CADDY_TLS=true, Caddy will use auto-HTTPS when CADDY_DOMAIN is set.
# If CADDY_TLS=false, Caddy serves plaintext HTTP (useful for local dev).
CADDY_TLS=true
CADDY_DOMAIN=
# External port exposed by Caddy
CADDY_PORT=443
